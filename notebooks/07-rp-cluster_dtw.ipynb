{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda9b8badabe1cb43a6bc145c902d456937",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster time-series using DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import dates\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys; sys.path.append('../')\n",
    "from src.data_loader.data_loader import load_google_mobility, load_deaths, load_interventions, load_counties, load_google_mobility_time_series\n",
    "from src.utils.dates import get_today, lag_date, date2str, str2date, get_format\n",
    "from src.utils.df_utils import get_date_columns\n",
    "from src.pandas.align import align_lagged_dates\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Mobility Last Updated 04-26\nDeaths Last Updated 04-26\n"
    }
   ],
   "source": [
    "# Time series data\n",
    "mobility, mobility_date = load_google_mobility()\n",
    "deaths, deaths_date = load_deaths(join_county_codes=False)\n",
    "interventions, interventions_date = load_interventions()\n",
    "\n",
    "# Static data\n",
    "counties, counties_date = load_counties()\n",
    "\n",
    "# Processed mobility -> time series\n",
    "mobility_ts, mobility_ts_date = load_google_mobility_time_series()\n",
    "\n",
    "print(f'Mobility Last Updated {mobility_ts_date}')\n",
    "print(f'Deaths Last Updated {deaths_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore places with FIPS missing\n",
    "deaths = deaths.dropna(axis=0, subset=['FIPS']).astype({'FIPS':'int32'})\n",
    "deaths = deaths.merge(counties['FIPS'], on='FIPS', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns that are dates\n",
    "death_dates = get_date_columns(deaths, return_dtimes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(row):\n",
    "    FIPS = row['FIPS']\n",
    "    pop = counties[counties['FIPS'] == FIPS]['POP_ESTIMATE_2018']\n",
    "    return(row[death_dates] / int(pop))\n",
    "    \n",
    "def get_onset_date(row, thresh = 5):\n",
    "    above = row[row > thresh]\n",
    "    if len(above) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return above.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize deaths by pop total\n",
    "deaths = deaths[['FIPS']+death_dates]\n",
    "\n",
    "deaths['onset'] = deaths[death_dates].apply(lambda row: get_onset_date(row), axis=1)\n",
    "\n",
    "deaths = deaths.dropna(axis=0, subset=['onset'])\n",
    "\n",
    "deaths[death_dates] = deaths.apply(lambda row: normalize(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_df = deaths[deaths['onset'].apply(lambda d: (str2date(death_dates[-1]) - str2date(d)).days >= 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTWDistance(s1, s2,w=5):\n",
    "    s1 = s1[s1 >= 0]\n",
    "    s2 = s2[s2 >= 0]\n",
    "    DTW={}\n",
    "    \n",
    "    w = max(w, abs(len(s1)-len(s2)))\n",
    "    \n",
    "    for i in range(-1,len(s1)):\n",
    "        for j in range(-1,len(s2)):\n",
    "            DTW[(i, j)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "  \n",
    "    for i in range(len(s1)):\n",
    "        for j in range(max(0, i-w), min(len(s2), i+w)):\n",
    "            dist= (s1[i]-s2[j])**2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\t\t\n",
    "    return np.sqrt(DTW[len(s1)-1, len(s2)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "deaths_np = deaths_df.apply(lambda row: [row[d] for d in death_dates if (str2date(row['onset']) - str2date(d)).days <= n-1],axis=1)\n",
    "\n",
    "deaths_np = [moving_average(d, n=n) for d in deaths_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(d) for d in deaths_np])\n",
    "distmat = pairwise_distances([np.hstack((d, [-1]*(max_length - len(d)))) for d in deaths_np], metric=DTWDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/intermediates/dtw_distmat.pickle', distmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/intermediates/dtw_distmat.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2cd1241e708b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdistmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/intermediates/dtw_distmat.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/intermediates/dtw_distmat.pickle'"
     ]
    }
   ],
   "source": [
    "distmat = np.load('../data/intermediates/dtw_distmat.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "3: 0.5450836737669922\n4: 0.5791789321626356\n5: 0.6282699246597335\n6: 0.6402778782923592\n7: 0.6265909873390871\n8: 0.4822592942842327\n9: 0.4783608323833335\n"
    }
   ],
   "source": [
    "n_clusters = np.arange(3,10,1)\n",
    "#linkage = ['average', 'ward', '']\n",
    "for n_clusters in np.arange(3,10,1):\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='average', affinity='precomputed').fit(distmat)\n",
    "    score = silhouette_score(distmat, clustering.labels_, metric='precomputed')\n",
    "    print(f'{n_clusters}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(labels, label, n = 5):\n",
    "    idxs = np.where(labels == label)[0][:n]\n",
    "    n = min(len(idxs), n)\n",
    "    fig,axes = plt.subplots(n,1,figsize=(1.5*n,1.5*n), sharex=True)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for i,idx in enumerate(idxs):\n",
    "        y = deaths_np[idx]\n",
    "        FIPS = deaths_df.iloc[idx]['FIPS']\n",
    "        l = ', '.join(counties[counties['FIPS'] == FIPS][['Area_Name', 'State']].values[0])\n",
    "        axes[i].plot(np.arange(len(y)), y, label=l)\n",
    "        axes[i].legend(loc='upper left')\n",
    "    axes[0].set_title(f'Cluster {label}, Size={len(np.where(labels == label)[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-03a4d251d629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clustering' is not defined"
     ]
    }
   ],
   "source": [
    "for label in clustering.labels_:\n",
    "    plot(clustering.labels_, label=label, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}