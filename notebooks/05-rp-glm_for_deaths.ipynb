{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "morf-dev",
   "display_name": "morf-dev"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a GLM to Estimate Residual Deaths\n",
    "\n",
    "## Potential Pipeline\n",
    "\n",
    "1. Consider the generalized additive model\n",
    "\n",
    "$$y_t = \\alpha + X_t\\beta_t + Z\\theta_t + f(t) + \\varepsilon_t$$\n",
    "\n",
    "For a give county, let \n",
    "$$\n",
    "\\begin{align}\n",
    "    u_t &= \\frac{\\text{deaths}}{ \\text{population total}} \\text{ at time } t \\\\\n",
    "    \\alpha &= \\text{constants} \\\\\n",
    "    X_t &= \\text{Lagged mobilities} \\text{(Also could consider incorporating $\\log u_{t-1}$)}\\\\\n",
    "    Z &= \\text{constant confounders (i.e. interventions)} \\\\\n",
    "    \\beta_t, \\theta_t &= \\text{coefficients to learn}\\\\\n",
    "    f(t) &= \\text{baseline death curve} \\\\\n",
    "    \\varepsilon_t &= \\text{noise}\n",
    "\\end{align}\n",
    "$$\n",
    "Then we model the confounder explained deaths as\n",
    "\n",
    "$$ y_t = \\log(u_t) = \\alpha + X_t\\beta_t + Z\\theta_t$$\n",
    "\n",
    "The residuals $f(t) + \\varepsilon_t = \\log(u_t) - (\\alpha + X_t\\beta_t + Z\\theta_t)$ are noisy baseline death curves.\n",
    "\n",
    "2. Cluster using time-series appropriate k-means (DTW metric)\n",
    "\n",
    "BIC or AIC to identify best set of clusters\n",
    "\n",
    "3. Explantory regression or exploratory data analysis within each cluster\n",
    "\n",
    "## Comments\n",
    "\n",
    "Requires all death time series to be the same length. Thus, need to truncate and only allow counties with that many timesetps after >5 deaths observed. Is that threshold cumulative or daily?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import dates\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sys; sys.path.append('../')\n",
    "from src.data_loader.data_loader import load_google_mobility, load_deaths, load_interventions, load_counties, load_google_mobility_time_series\n",
    "from src.utils.dates import get_today, lag_date, date2str, str2date, get_format\n",
    "from src.utils.df_utils import get_date_columns\n",
    "from src.pandas.align import align_lagged_dates\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Mobility Last Updated 04-26\nDeaths Last Updated 04-26\n"
    }
   ],
   "source": [
    "# Time series data\n",
    "mobility, mobility_date = load_google_mobility()\n",
    "deaths, deaths_date = load_deaths(join_county_codes=False)\n",
    "interventions, interventions_date = load_interventions()\n",
    "\n",
    "# Static data\n",
    "counties, counties_date = load_counties()\n",
    "\n",
    "# Processed mobility -> time series\n",
    "mobility_ts, mobility_ts_date = load_google_mobility_time_series()\n",
    "\n",
    "print(f'Mobility Last Updated {mobility_ts_date}')\n",
    "print(f'Deaths Last Updated {deaths_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore places with FIPS missing\n",
    "deaths = deaths.dropna(axis=0, subset=['FIPS']).astype({'FIPS':'int32'})\n",
    "deaths = deaths.merge(counties['FIPS'], on='FIPS', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns that are dates\n",
    "death_dates = get_date_columns(deaths, return_dtimes=False)\n",
    "mobility_dates = get_date_columns(mobility_ts, return_dtimes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths = deaths[['FIPS']+death_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onset_date(row, thresh = 5):\n",
    "    above = row[row > thresh]\n",
    "    if len(above) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return above.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths['onset'] = deaths[death_dates].apply(lambda row: get_onset_date(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths = deaths.dropna(axis=0, subset=['onset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diffs = [(str2date(death_dates[-1]) - str2date(d)).days for d in deaths['onset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(row):\n",
    "    FIPS = row['FIPS']\n",
    "    pop = counties[counties['FIPS'] == FIPS]['POP_ESTIMATE_2018']\n",
    "    return(row[death_dates] / int(pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize deaths by pop total\n",
    "deaths[death_dates] = deaths.apply(lambda row: normalize(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get deaths, lagged mobility, and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_df = deaths[deaths['onset'].apply(lambda d: (str2date(death_dates[-1]) - str2date(d)).days >= 14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get days_past the onset of each county (onset being first case of deaths==5)\n",
    "for days_past in range(15):\n",
    "    deaths_df[f'y{days_past}'] = deaths_df.apply(\n",
    "        lambda row: row[lag_date(row['onset'], days_past, backwards=False, return_date=False)],axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility lagged covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lagged_mobility(date, FIPS):\n",
    "    mob_dates = [lag_date(date, l, return_date=False) for l in range(13,25,1)]\n",
    "    try:\n",
    "        return(mobility_ts[mobility_ts['FIPS'] == FIPS][mob_dates])\n",
    "    except:\n",
    "        np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make covariate matrices\n",
    "covariates = deaths_df[['FIPS', 'onset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time dependent lagged mobility\n",
    "for days_past in range(15):\n",
    "    key = f'mobility_y{days_past}'\n",
    "    covariates[key] = covariates.apply(\n",
    "        lambda row: get_lagged_mobility(\n",
    "            lag_date(row['onset'], days_past, backwards=False, return_date=False), row['FIPS']\n",
    "    ), axis=1)\n",
    "    covariates = covariates.dropna(axis=0, subset=[key])\n",
    "    covariates[key] = covariates[key].apply(lambda x: x.to_numpy().reshape(-1))\n",
    "    covariates = covariates[covariates[key].apply(lambda x: len(x) == 12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_covariates = deaths_df[['FIPS', 'onset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constant covariates of interest\n",
    "intervention_covs = [\n",
    "    'stay at home',\n",
    "    'restaurant dine-in',\n",
    "    'public schools',\n",
    "    '>50 gatherings',\n",
    "    'entertainment/gym'\n",
    "]\n",
    "\n",
    "county_covs = [\n",
    "    'Rural-urban_Continuum Code_2013',\n",
    "    'Urban_Influence_Code_2013',\n",
    "    'Density per square mile of land area - Population',\n",
    "    'Total_age65plus',\n",
    "    'Total Hospitals (2019)',\n",
    "    'MEDHHINC_2018'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add intervention covariates\n",
    "constant_covariates = constant_covariates.merge(interventions[['FIPS'] + intervention_covs], on='FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set intervention date to days before onset\n",
    "constant_covariates[intervention_covs] = constant_covariates.apply(lambda row: pd.Series([(str2date(row['onset']) - str2date(x)).days if not pd.isna(x) else 0 for x in row[intervention_covs]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add county covariates\n",
    "constant_covariates = constant_covariates.merge(counties[['FIPS'] + county_covs], on='FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize age65plus by total population\n",
    "constant_covariates['Total_age65plus'] = constant_covariates.apply(lambda row: row['Total_age65plus'] / int(counties[counties['FIPS'] == row['FIPS']]['POP_ESTIMATE_2018']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FIPS</th>\n      <th>stay at home</th>\n      <th>restaurant dine-in</th>\n      <th>public schools</th>\n      <th>&gt;50 gatherings</th>\n      <th>entertainment/gym</th>\n      <th>Rural-urban_Continuum Code_2013</th>\n      <th>Urban_Influence_Code_2013</th>\n      <th>Density per square mile of land area - Population</th>\n      <th>Total_age65plus</th>\n      <th>Total Hospitals (2019)</th>\n      <th>MEDHHINC_2018</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1017</td>\n      <td>0</td>\n      <td>16</td>\n      <td>19</td>\n      <td>15</td>\n      <td>7</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>57.4</td>\n      <td>0.195210</td>\n      <td>0.694600</td>\n      <td>39917.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1055</td>\n      <td>7</td>\n      <td>23</td>\n      <td>26</td>\n      <td>22</td>\n      <td>14</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>195.2</td>\n      <td>0.190115</td>\n      <td>2.118018</td>\n      <td>44903.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1073</td>\n      <td>8</td>\n      <td>15</td>\n      <td>18</td>\n      <td>14</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>592.5</td>\n      <td>0.158573</td>\n      <td>13.623375</td>\n      <td>55013.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   FIPS  stay at home  restaurant dine-in  public schools  >50 gatherings  \\\n0  1017             0                  16              19              15   \n1  1055             7                  23              26              22   \n2  1073             8                  15              18              14   \n\n   entertainment/gym  Rural-urban_Continuum Code_2013  \\\n0                  7                              6.0   \n1                 14                              3.0   \n2                  6                              1.0   \n\n   Urban_Influence_Code_2013  \\\n0                        5.0   \n1                        2.0   \n2                        1.0   \n\n   Density per square mile of land area - Population  Total_age65plus  \\\n0                                               57.4         0.195210   \n1                                              195.2         0.190115   \n2                                              592.5         0.158573   \n\n   Total Hospitals (2019)  MEDHHINC_2018  \n0                0.694600        39917.0  \n1                2.118018        44903.0  \n2               13.623375        55013.0  "
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_covariates.drop(labels='onset', axis=1).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_df = reduce(lambda x,y: pd.merge(x,y,on='FIPS', how='inner'), [deaths_df, covariates, constant_covariates.drop(labels='onset', axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "y = Xy_df[f'y{t}']\n",
    "X =  Xy_df[intervention_covs + county_covs + [f'mobility_y{days_past}']]\n"
   ]
  }
 ]
}